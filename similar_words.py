# -*- coding: utf-8 -*-
"""similar_words

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pBXC0PvrKhKjjVw4tVPc_mdooaDhzmw_
"""

# from typing import final
from nltk.stem import WordNetLemmatizer
import nltk
from collections import defaultdict

# nltk.download('wordnet')
lemmatizer = WordNetLemmatizer()


def getWordLemma(words):
    distancedict = defaultdict(set)
    for w in words:
        wlower = w.lower()
        #w=w.replace("_", " ")
        if "_" not in w:
            #print(w, " : ", lemmatizer.lemmatize(w))
            wordlemma = lemmatizer.lemmatize(wlower)

        else:
            w_list = w.split("_")
            # print(w_list)
            w_newlist = []
            for singlew in w_list:
                #print(singlew, " : ", lemmatizer.lemmatize(singlew))
                singlew = singlew.lower()
                w_newlist.append(lemmatizer.lemmatize(singlew))

            wordlemma = ' '.join(w_newlist)

        distancedict[wordlemma].add(w)
    return distancedict

# the distance is calculated after the lemmatization


def calculateLemmaDistance(distancedict):
    merged = defaultdict(lambda: False)
    distancedictFinal = defaultdict(set)
    for key1 in distancedict:
        for key2 in distancedict:
            if key1 != key2:
                distance = nltk.edit_distance(key1, key2, transpositions=False)
                # print(distance)
                #print(key1, key2, distance)
                #if key1 == "gangland killing": print(key1, key2, distance)
                if distance <= 3 and merged[key2] == False:
                    merged[key1] = True
                    merged[key2] = True
                    newSet = distancedictFinal[key1]
                    newSet.update(distancedict[key1])
                    newSet.update(distancedict[key2])
                    distancedictFinal[key1] = newSet

                    #print(key1, key2)
                    # print(distancedict[key1])
                    #distancedictFinal[key1] = defaultdict[key1].union(defaultdict[key2])
    return distancedictFinal, merged


def processMergedFalse(distancedict, distancedictFinal, merged):
    for key in distancedict:
        #print(key, distancedict[key])
        if merged[key] == False:
            distancedictFinal[key] = distancedict[key]


def remove_similar_words(words):

    distancedict = getWordLemma(words)
    distancedictFinal, merged = calculateLemmaDistance(distancedict)
    processMergedFalse(distancedict, distancedictFinal, merged)

    final_rep_words = []

    for key in sorted(distancedictFinal.keys()):
        final_rep_words.append(key)

    return final_rep_words
